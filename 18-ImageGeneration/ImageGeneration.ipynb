{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "UsVbVseYJ1fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "YM3mELQEKVa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(mnist_digits)"
      ],
      "metadata": {
        "id": "Pr1FyovJKVdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "2CVPjjotKVfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "LATENT_DIM = 2"
      ],
      "metadata": {
        "id": "Wh1rARz0KViI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "                  dataset\n",
        "                 .shuffle(buffer_size=1024, reshuffle_each_iteration=True)\n",
        "                 .batch(BATCH_SIZE)\n",
        "                 .prefetch(tf.data.AUTOTUNE)\n",
        "                 )"
      ],
      "metadata": {
        "id": "Cp7YQoViMphz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "QO9PrXj5M7ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    mean, log_var = inputs\n",
        "    return mean + tf.math.exp(0.5*log_var)*tf.random.normal(shape = (tf.shape(mean)[0], tf.shape(mean)[1]))"
      ],
      "metadata": {
        "id": "kWYM7G5xPn1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(32, 3, activation='relu', strides=2, padding='same')(encoder_inputs)\n",
        "x = Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "\n",
        "mean = Dense(LATENT_DIM,)(x)\n",
        "log_var = Dense(LATENT_DIM,)(x)\n",
        "\n",
        "z = Sampling()([mean,log_var])\n",
        "\n",
        "encoder_model = Model(encoder_inputs,[z,mean,log_var], name='encoder')\n",
        "encoder_model.summary()"
      ],
      "metadata": {
        "id": "mcmrnXcnNCWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_inputs = Input(shape=(LATENT_DIM,))\n",
        "\n",
        "\n",
        "x = Dense(7*7*64, activation='relu')(latent_inputs)\n",
        "x = Reshape((7,7,64))(x)\n",
        "\n",
        "x = Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
        "\n",
        "decoder_output = Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
        "decoder_model = Model(latent_inputs,decoder_output,name='decoder')\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "id": "t8C1O6AcNCwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae_input = Input(shape=(28,28,1), name=\"vae_input\")\n",
        "z,_,_ = encoder_model(vae_input)\n",
        "output = decoder_model(z)\n",
        "vae = Model(vae_input, output, name=\"vae\")\n",
        "vae.summary()"
      ],
      "metadata": {
        "id": "FPvRFmMpNC2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPTIMIZER = Adam(learning_rate=1e-3)\n",
        "EPOCH = 30"
      ],
      "metadata": {
        "id": "fqDQy3ffNCyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true,y_pred,mean,log_var):\n",
        "\n",
        "  loss_rec = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(y_true,y_pred), axis = (1,2)))\n",
        "\n",
        "  loss_reg = -0.5 * (1 + log_var - tf.square(mean) - tf.exp(log_var))\n",
        "\n",
        "  return loss_rec+tf.reduce_mean(tf.reduce_sum(loss_reg, axis=1))"
      ],
      "metadata": {
        "id": "AQcxtCzKNC0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def training_block(x_batch):\n",
        "  with tf.GradientTape() as recorder:\n",
        "    z,mean,log_var = encoder_model(x_batch)\n",
        "    y_pred = decoder_model(z)\n",
        "    y_true = x_batch\n",
        "    loss = custom_loss(y_true,y_pred, mean, log_var)\n",
        "\n",
        "  partial_derivatives = recorder.gradient(loss,vae.trainable_weights)\n",
        "  OPTIMIZER.apply_gradients(zip(partial_derivatives, vae.trainable_weights))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "W3fiWA6RWF-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_learn(epochs):\n",
        "  for epoch in range(1,epochs+1):\n",
        "    print('Training starts for epoch number {}'.format(epoch))\n",
        "\n",
        "    for step, x_batch in enumerate(train_dataset):\n",
        "      loss = training_block(x_batch)\n",
        "    print('Training Loss is: ', loss)\n",
        "  print('Training Complete!!!')"
      ],
      "metadata": {
        "id": "PLoGeX5dYfxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_learn(EPOCH)"
      ],
      "metadata": {
        "id": "PPOxmf94ZdWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(tf.keras.Model):\n",
        "  def __init__(self, encoder_model, decoder_model):\n",
        "    super(VAE, self).__init__()\n",
        "    self.encoder = encoder_model\n",
        "    self.decoder = decoder_model\n",
        "    self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.loss_tracker]\n",
        "\n",
        "  def train_step(self,x_batch): # creating fit method for custom models\n",
        "    with tf.GradientTape() as recorder:\n",
        "      z,mean,log_var = encoder_model(x_batch)\n",
        "      y_pred = decoder_model(z)\n",
        "      y_true = x_batch\n",
        "      loss = custom_loss(y_true,y_pred, mean, log_var)\n",
        "\n",
        "    partial_derivatives = recorder.gradient(loss,self.trainable_weights)\n",
        "    OPTIMIZER.apply_gradients(zip(partial_derivatives, self.trainable_weights))\n",
        "\n",
        "    self.loss_tracker.update_state(loss)\n",
        "\n",
        "    return {\"loss\":self.loss_tracker.result()}"
      ],
      "metadata": {
        "id": "mlWuUNyXFt4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(encoder_model, decoder_model)\n",
        "model.compile(optimizer=OPTIMIZER)\n",
        "model.fit(train_dataset, epochs=20, batch_size=128)"
      ],
      "metadata": {
        "id": "CXYjYhpOHv9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale = 1\n",
        "n = 16"
      ],
      "metadata": {
        "id": "QcJtFAhnbCW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_x = np.linspace(-scale,scale,n)\n",
        "grid_y = np.linspace(-scale,scale,n)"
      ],
      "metadata": {
        "id": "4xg-rEQXZlDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_x, grid_y"
      ],
      "metadata": {
        "id": "KIYtxTyMbFcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "k = 0\n",
        "\n",
        "for i in grid_x:\n",
        "  for j in grid_y:\n",
        "    ax = plt.subplot(n,n, k+1)\n",
        "\n",
        "    input = tf.constant([[i,j]])\n",
        "    out = model.decoder.predict(input)[0][...,0]\n",
        "    # out = vae.layers[2].predict(input)[0][...,0]\n",
        "    plt.imshow(out, cmap='Greys_r')\n",
        "    plt.axis('off')\n",
        "    k+=1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s5rm97YkbFf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), _  = tf.keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.expand_dims(x_train, -1).astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "6RlJMXtobbRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z,_,_ = vae.layers[1].predict(x_train)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.scatter(z[:,0],z[:,1], c=y_train)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KEjhnSs1bbTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdCdLZxVbbVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}